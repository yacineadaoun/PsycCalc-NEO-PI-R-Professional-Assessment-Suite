from __future__ import annotations

import io
import json
import hashlib
from dataclasses import asdict
from pathlib import Path
from typing import Dict, Any, Tuple

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image
import matplotlib.pyplot as plt

from neo_pir_omr.core.engine import (
    OMRScanner,
    OMRConfig,
    load_scoring_key_from_bytes,
    apply_protocol_rules,
    compute_scores,
)
from neo_pir_omr.core.security import SecurityPolicy, validate_file_bytes


st.set_page_config(
    page_title="NEO PIâ€‘R â€” OMR Scanner & Scoring (Scientific)",
    page_icon="ğŸ§¾",
    layout="wide",
)

st.markdown(
    """
    <style>
      .block-container {padding-top: 1.2rem;}
      div[data-testid="stMetricValue"] {font-size: 1.6rem;}
      .tiny {opacity:.85; font-size: .9rem;}
      .card {padding: 1rem 1.2rem; border-radius: 18px; border: 1px solid rgba(255,255,255,.08);
             background: rgba(255,255,255,.03);}
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ§¾ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø¶ÙˆØ¦ÙŠ (OMR) Ù„Ø§Ø®ØªØ¨Ø§Ø± NEO PIâ€‘R")
st.caption("Ù‡Ø¯Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚: **Ù…Ø³Ø­ ÙˆØ±Ù‚Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©** âœ **Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª** âœ **Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø¹Ù„Ù…ÙŠØ§Ù‹** âœ **Ø¥Ø®Ø±Ø§Ø¬ ØªÙ‚Ø±ÙŠØ± ÙˆØ±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©**.")


def _hash_bytes(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()[:16]


def _download(label: str, data: bytes, name: str, mime: str):
    st.download_button(label, data=data, file_name=name, mime=mime, use_container_width=True)


def _load_norms_df() -> pd.DataFrame:
    p = Path(__file__).resolve().parents[1] / "data" / "norms.csv"
    return pd.read_csv(p)


def _pick_norms(norms: pd.DataFrame, scale_type: str, scale: str, sex: str, age: int) -> Tuple[float, float]:
    sub = norms[
        (norms["scale_type"] == scale_type)
        & (norms["scale"] == scale)
        & (norms["sex"] == sex)
        & (norms["age_min"] <= age)
        & (norms["age_max"] >= age)
    ]
    if sub.empty:
        raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ø§ÙŠÙŠØ± (norms) Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø¬Ù†Ø³/Ø§Ù„Ø¹Ù…Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯ÙŠÙ†.")
    row = sub.iloc[0]
    return float(row["mean"]), float(row["sd"])


def _z_t(raw: float, mean: float, sd: float) -> Dict[str, float]:
    if sd <= 0:
        raise ValueError("Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ SD ØºÙŠØ± ØµØ­ÙŠØ­Ø© ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±.")
    z = (raw - mean) / sd
    t = 50.0 + 10.0 * z
    return {"z": float(z), "t": float(t)}


def _plot_curve(domain_t: Dict[str, float]):
    labels = ["N", "E", "O", "A", "C"]
    y = [domain_t.get(k, np.nan) for k in labels]
    x = np.arange(len(labels))

    fig = plt.figure(figsize=(7.5, 3.2))
    ax = fig.add_subplot(111)
    ax.plot(x, y, marker="o")
    ax.set_xticks(x, labels)
    ax.set_ylim(20, 80)
    ax.set_ylabel("T-score")
    ax.set_title("Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¹Ø§Ù… Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© (T-scores)")
    ax.grid(True, alpha=0.25)
    st.pyplot(fig, clear_figure=True)


def _plot_radar(domain_t: Dict[str, float]):
    labels = ["N", "E", "O", "A", "C"]
    values = [domain_t.get(k, np.nan) for k in labels]
    values = values + values[:1]
    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
    angles = angles + angles[:1]

    fig = plt.figure(figsize=(5.2, 5.2))
    ax = fig.add_subplot(111, polar=True)
    ax.plot(angles, values)
    ax.fill(angles, values, alpha=0.15)
    ax.set_thetagrids(np.degrees(angles[:-1]), labels)
    ax.set_ylim(20, 80)
    ax.set_title("Ø®Ø±ÙŠØ·Ø© Ø±Ø§Ø¯Ø§Ø±ÙŠØ© Ù„Ù„Ù…Ø¬Ø§Ù„Ø§Øª (T-scores)", pad=18)
    st.pyplot(fig, clear_figure=True)


policy = SecurityPolicy(max_upload_mb=15)

with st.sidebar:
    st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ©")
    st.caption("Ø§Ø¶Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ØºØ§Ù„Ø¨Ø§Ù‹ ÙƒØ§ÙÙŠØ©.")

    mark_threshold = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© (mark_threshold)", 0.5, 6.0, 1.7, 0.1)
    ambiguity_gap = st.slider("ÙØ§Ø±Ù‚ Ø§Ù„ØºÙ…ÙˆØ¶ (ambiguity_gap)", 0.1, 6.0, 0.9, 0.1)

    st.divider()
    st.subheader("Ø§Ù„Ø­Ø¨Ø±")
    detect_blue = st.checkbox("Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø­Ø¨Ø± Ø§Ù„Ø£Ø²Ø±Ù‚", value=True)
    detect_black = st.checkbox("Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ø­Ø¨Ø± Ø§Ù„Ø£Ø³ÙˆØ¯", value=True)
    black_dark_thresh = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„Ø³ÙˆØ§Ø¯ (black_dark_thresh)", 60, 180, 110, 1)
    black_baseline_quantile = st.slider("Baseline quantile Ù„Ù„Ø­Ø¨Ø± Ø§Ù„Ø£Ø³ÙˆØ¯", 0.0, 50.0, 15.0, 1.0)

    st.divider()
    st.subheader("Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± ÙˆØ§Ù„ØªÙ‚Ù†ÙŠÙ†")
    sex = st.selectbox("Ø§Ù„Ø¬Ù†Ø³ (Ù„Ù„Ù€ norms)", options=["M", "F"], index=0)
    age = st.number_input("Ø§Ù„Ø¹Ù…Ø±", min_value=10, max_value=90, value=25, step=1)
    st.caption("Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ **ØªØ¬Ø±ÙŠØ¨ÙŠØ©** Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„Ù norms.csv. ÙŠÙ…ÙƒÙ†Ùƒ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ù…Ø¹Ø§ÙŠÙŠØ±Ùƒ Ø§Ù„Ø±Ø³Ù…ÙŠØ©.")

    st.divider()
    st.subheader("Ù…Ù„ÙØ§Øª")
    key_file = st.file_uploader("Ù…Ù„Ù Ù…ÙØªØ§Ø­ Ø§Ù„ØªØµØ­ÙŠØ­ scoring_key.csv", type=["csv"])
    norms_file = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± norms.csv (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type=["csv"])


left, right = st.columns([1.25, 0.75], vertical_alignment="top")
with left:
    img_file = st.file_uploader("ğŸ“· Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©/Ø³ÙƒØ§Ù†Ø± ÙˆØ±Ù‚Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", type=["jpg", "jpeg", "png", "webp"])
with right:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("Ù†ØµØ§Ø¦Ø­ Ù„Ù†ØªÙŠØ¬Ø© Ø¯Ù‚ÙŠÙ‚Ø©")
    st.markdown(
        "- ØµÙˆØ±Ø© ÙˆØ§Ø¶Ø­Ø© Ø¨Ø¯ÙˆÙ† Ø§Ù‡ØªØ²Ø§Ø²
"
        "- Ø§Ù„ÙˆØ±Ù‚Ø© ÙƒØ§Ù…Ù„Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¥Ø·Ø§Ø±
"
        "- Ø¥Ø¶Ø§Ø¡Ø© Ù…ØªØ¬Ø§Ù†Ø³Ø© Ø¨Ø¯ÙˆÙ† Ø¸Ù„ Ù‚ÙˆÙŠ
"
        "- ØªØ¬Ù†Ø¨ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ Ø§Ù„Ù„Ø§Ù…Ø¹
"
        "- Ø§Ø³ØªØ®Ø¯Ù… Ù‚Ù„Ù… Ø£Ø²Ø±Ù‚/Ø£Ø³ÙˆØ¯ ÙˆØ§Ø¶Ø­",
    )
    st.markdown("</div>", unsafe_allow_html=True)

if not img_file:
    st.stop()

validate_file_bytes(img_file.name, img_file.size, policy)
img_bytes = img_file.getvalue()
img_hash = _hash_bytes(img_bytes)

pil_img = Image.open(io.BytesIO(img_bytes)).convert("RGB")


if key_file is not None:
    scoring_key = load_scoring_key_from_bytes(key_file.getvalue())
else:
    default_key_path = Path(__file__).resolve().parents[1] / "data" / "scoring_key.csv"
    scoring_key = load_scoring_key_from_bytes(default_key_path.read_bytes())


if norms_file is not None:
    norms_df = pd.read_csv(io.BytesIO(norms_file.getvalue()))
else:
    norms_df = _load_norms_df()

cfg = OMRConfig(
    mark_threshold=float(mark_threshold),
    ambiguity_gap=float(ambiguity_gap),
    detect_blue=bool(detect_blue),
    detect_black=bool(detect_black),
    black_dark_thresh=int(black_dark_thresh),
    black_baseline_quantile=float(black_baseline_quantile),
)

scanner = OMRScanner(cfg=cfg)


if "scan_cache" not in st.session_state:
    st.session_state.scan_cache = {}

cfg_sig = json.dumps(asdict(cfg), sort_keys=True, ensure_ascii=False)
cache_key = f"{img_hash}:{_hash_bytes(cfg_sig.encode('utf-8'))}:key"

run_scan = st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø³Ø­ ÙˆØ§Ù„Ø­Ø³Ø§Ø¨", use_container_width=True)

if run_scan:
    with st.spinner("Ø¬Ø§Ø±Ù Ø§Ù„Ù…Ø³Ø­â€¦"):
        result = scanner.scan_pil(pil_img, scoring_key)
    st.session_state.scan_cache[cache_key] = result

result = st.session_state.scan_cache.get(cache_key)
if result is None:
    st.info("Ø§Ø¶ØºØ· Ø²Ø± **ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø³Ø­ ÙˆØ§Ù„Ø­Ø³Ø§Ø¨** Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
    st.stop()


st.success(f"ØªÙ… Ø§Ù„Ù…Ø³Ø­ Ø¨Ù†Ø¬Ø§Ø­ âœ…  (scan_id: {result.scan_id})")

m = result.diagnostics.get("stats", {})
proto = result.protocol or {}

m1, m2, m3, m4 = st.columns(4)
m1.metric("Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ§Ø±ØºØ©", int(proto.get("n_blank", 0)))
m2.metric("Ø§Ù„ØºØ§Ù…Ø¶Ø©", int(m.get("ambiguous", 0)))
m3.metric("Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©", int(m.get("low_conf", 0)))
m4.metric("ØªÙ…Ù‘ ØªØ¹ÙˆÙŠØ¶Ù‡Ø§", int(proto.get("imputed", 0)))

with st.expander("ğŸ” ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© (Ù„Ù„ØªØ­Ù‚Ù‚)", expanded=False):
    vals = list(result.responses_final.values())
    st.json(
        {
            "valid_protocol": bool(proto.get("valid", True)),
            "reasons": proto.get("reasons", []),
            "n_items": len(vals),
            "n_-1_blank": int(sum(1 for v in vals if v == -1)),
            "sample_1_20": {k: int(result.responses_final.get(k, -1)) for k in range(1, 21)},
            "thresholds": result.diagnostics.get("thresholds", {}),
            "table_bbox": result.diagnostics.get("table_bbox", {}),
        }
    )

v1, v2 = st.columns([1, 1])
with v1:
    st.subheader("Overlay (Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ¯)")
    st.image(result.overlay_bgr[:, :, ::-1], use_container_width=True)
with v2:
    st.subheader("Mask (Ø­Ø¨Ø±/ØªØ­Ø¯ÙŠØ¯ â€” Debug)")
    st.image(result.debug_mask, use_container_width=True)


st.subheader("ğŸ“Œ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (Raw Scores)")
c1, c2 = st.columns(2)
with c1:
    st.markdown("**Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© (N/E/O/A/C)**")
    st.json(result.domain_scores)
with c2:
    st.markdown("**Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª (Facets)**")
    st.json(result.facette_scores)


st.subheader("ğŸ“ˆ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ© (Z / T)")
domain_t: Dict[str, float] = {}
domain_norm_detail: Dict[str, Any] = {}

try:
    for d, raw in result.domain_scores.items():
        mean, sd = _pick_norms(norms_df, scale_type="domain", scale=d, sex=sex, age=int(age))
        res = _z_t(float(raw), mean, sd)
        domain_t[d] = res["t"]
        domain_norm_detail[d] = {"raw": int(raw), "mean": mean, "sd": sd, **res}
except Exception as e:
    st.warning(f"ØªØ¹Ø°Ø± Ø­Ø³Ø§Ø¨ T-scores Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±: {e}")
    domain_norm_detail = {}

if domain_norm_detail:
    st.dataframe(pd.DataFrame(domain_norm_detail).T, use_container_width=True)

    g1, g2 = st.columns([1.2, 0.8])
    with g1:
        _plot_curve(domain_t)
    with g2:
        _plot_radar(domain_t)


st.subheader("ğŸ§‘â€ğŸ”¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¨Ø´Ø±ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©) + Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨")
st.caption("Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ±Ø§ØºØ§Øª/ØºÙ…ÙˆØ¶. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ ØªØªÙ… Ø¹Ø¨Ø± Ø²Ø± Ù…Ø³ØªÙ‚Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±.")

flagged = []
for item_id in range(1, 241):
    md = result.meta.get(item_id, {})
    if md.get("blank") or md.get("ambiguous") or float(md.get("confidence", 1.0)) < 0.55:
        flagged.append(item_id)

with st.expander(f"ÙØªØ­ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ© â€” Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø­ØªØ§Ø¬Ø© ({len(flagged)})", expanded=False):
    if not flagged:
        st.success("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù†Ø§ØµØ± ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© âœ…")
    else:
        st.warning("Ù‚Ù… Ø¨ØªØ¹Ø¯ÙŠÙ„ Ù…Ø§ ÙŠÙ„Ø²Ù… ÙÙ‚Ø·ØŒ Ø«Ù… Ø§Ø¶ØºØ· Ø²Ø± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨.")
        page_size = 12
        page = st.number_input(
            "Ø§Ù„ØµÙØ­Ø©",
            min_value=1,
            max_value=max(1, (len(flagged) + page_size - 1) // page_size),
            value=1,
            step=1,
        )
        start = (page - 1) * page_size
        end = min(len(flagged), start + page_size)

        corrections: Dict[int, int] = {}
        for item_id in flagged[start:end]:
            current = int(result.responses_raw.get(item_id, -1))
            md = result.meta.get(item_id, {})
            col1, col2 = st.columns([0.6, 1.4])
            with col1:
                st.markdown(f"**Item {item_id}**")
                st.markdown(f"<span class='tiny'>confidence: {float(md.get('confidence', 0.0)):.2f}</span>", unsafe_allow_html=True)
            with col2:
                choice = st.selectbox(
                    f"ØªØµØ­ÙŠØ­ Item {item_id}",
                    options=[-1, 0, 1, 2, 3, 4],
                    index=[-1, 0, 1, 2, 3, 4].index(current if current in [-1,0,1,2,3,4] else -1),
                    help="-1 = ÙØ§Ø±Øº ; 0..4 = Ø®ÙŠØ§Ø± Ù…Ø­Ø¯Ø¯",
                    key=f"corr_{item_id}",
                )
                if int(choice) != current:
                    corrections[item_id] = int(choice)

        if st.button("âœ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨", use_container_width=True):
            final_resp = dict(result.responses_final)
            final_resp.update(corrections)

            final_after_proto, proto2 = apply_protocol_rules(cfg, final_resp)
            facette_scores2, domain_scores2 = compute_scores(final_after_proto, scoring_key)

            st.success("ØªÙ…Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ âœ…")
            st.json({"protocol": proto2, "domain_scores": domain_scores2, "facette_scores": facette_scores2})


st.subheader("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
resp_csv = io.StringIO()
resp_csv.write("item,choice
")
for item_id in range(1, 241):
    resp_csv.write(f"{item_id},{int(result.responses_final.get(item_id, -1))}
")

colx, coly, colz = st.columns(3)
with colx:
    _download("responses.csv", resp_csv.getvalue().encode("utf-8"), "responses.csv", "text/csv")
with coly:
    _download(
        "scores.json",
        json.dumps(
            {
                "scan_id": result.scan_id,
                "protocol": result.protocol,
                "domain_scores_raw": result.domain_scores,
                "facette_scores_raw": result.facette_scores,
                "normed": domain_norm_detail,
                "cfg": asdict(cfg),
            },
            ensure_ascii=False,
            indent=2,
        ).encode("utf-8"),
        "scores.json",
        "application/json",
    )
with colz:
    _download(
        "audit.json",
        json.dumps(
            {
                "diagnostics": result.diagnostics,
                "meta": result.meta,
            },
            ensure_ascii=False,
            indent=2,
        ).encode("utf-8"),
        "audit.json",
        "application/json",
    )
